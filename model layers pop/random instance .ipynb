{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Raw Cell Format",
    "colab": {
      "name": "pop_layer_model2_3dense Bugggg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helmana/DLeeg/blob/master/model%20layers%20pop/random%20instance%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgLxG3mBz0Fx",
        "colab_type": "code",
        "outputId": "bcd49e79-68c9-49ae-eda9-5b08e6bf9896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        ">> Random instance \n",
        "\n",
        "model3 -  1 layer pop\n",
        "\n",
        "subject number = 109 >> 90 train subject  + 19 new subject \n",
        "channel number = 20 >> [21,23,29,31,33,35,36,40,8,10,12,41,46,48,50,52,54,60,61,62]\n",
        "\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n109 subject\\n1 channel (Oz)\\ntask: REO \\nepoch: 60\\nseed = 14\\n\\nTrainResult ([loss , acc])= [0.12535213132612147, 0.959957998996991]\\nValidationResult ([loss , acc])= [0.1946041866179451, 0.9351468373493976]\\nTestResult ([loss , acc])= [0.20246034180243572, 0.9319486027944112]\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fM152eYkDEi0",
        "outputId": "06c05452-1ab4-49ce-93dc-978f0544b50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v_9QlgWXuZ2E",
        "outputId": "9a7f1fa6-3efe-40c9-bed6-6af3ca5cc569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/7c/ad1b52a3fdd4be8f55e183f1eff7d76f48cd1bee83c5630f9c26770e032e/mne-0.19.2-py3-none-any.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.17.4)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.19.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ugNHdREkvO6h",
        "outputId": "58dedc25-d81b-43e4-c3be-b59d6b1b70a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Rivision:\n",
        "980806:\n",
        "  First version.\n",
        "  \n",
        "  \n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nRivision:\\n980806:\\n  First version.\\n  \\n  \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HtvZeqTcuZ2M",
        "colab": {}
      },
      "source": [
        "# Parameters:\n",
        "\n",
        "EpochNum=60\n",
        "subject_numberT=109\n",
        "RemoveBaseLine=0\n",
        "Orthogonal=1\n",
        "task_index = [1] # task: REO\n",
        "list_channel=[21,23,29,31,33,35,36,40,8,10,12,41,46,48,50,52,54,60,61,62]\n",
        "TryStr='Try1'\n",
        "seed = 14\n",
        "\n",
        "task_number=1\n",
        "task_time = 60\n",
        "sampel_number_per_sec =  160 # sampel rate\n",
        "total_sampel_number =  sampel_number_per_sec *task_time # 60*160\n",
        "#sample_shift = 4 #step len\n",
        "inner_sample_shift = 4 # inner step len\n",
        "outer_sample_shift =8  # outer step len\n",
        "window_len= 20\n",
        "batch_size=64\n",
        "\n",
        "#Search_Space_Channel = [21,23,29,31,33,35,36,40,8,10,12,41,46,48,50,52,54,60,61,62]\n",
        "#Search_Space_Channel_Name=[\"Fp1\",\"Fp2\",\"F7\",\"F3\",\"Fz\",\"F4\",\"F8\",\"T7\",\"C3\",\"Cz\",\"C4\",\"T8\",\"P7\",\"P3\",\"Pz\",\"P4\",\"P8\",\"O1\",\"Oz\",\"O2\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n5TM1aaTaDZZ",
        "outputId": "9302ed3f-b157-4b9a-93b8-ee8a07622e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# For Visualization\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
        "\n",
        "# General use\n",
        "import itertools\n",
        "from itertools import combinations \n",
        "\n",
        "import os.path\n",
        "from scipy.spatial import distance\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "import pytz\n",
        "from time import gmtime, strftime\n",
        "\n",
        "# For model training\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import regularizers\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras import backend as KerasBackend\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "\n",
        "# EEG Tools\n",
        "import mne\n",
        "from mne.preprocessing import create_ecg_epochs, create_eog_epochs\n",
        "from mne import io\n",
        "from mne import viz\n",
        "from mne import Epochs, io, pick_types\n",
        "from mne.event import define_target_events\n",
        "from mne.time_frequency import psd_welch\n",
        "print(__doc__)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numba/decorators.py:146: RuntimeWarning: Caching is not available when the 'parallel' target is in use. Caching is now being disabled to allow execution to continue.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EMBxiZ8KvXUP",
        "colab": {}
      },
      "source": [
        "# load dataset in array\n",
        "task_number= len(task_index)\n",
        "\n",
        "# load dataset in array\n",
        "list_raw_fnames = [[0]*task_number]*subject_numberT\n",
        "for x in range(subject_numberT):\n",
        "  list_raw_fnames[x] = mne.datasets.eegbci.load_data(x+1,task_index,path='/content/drive/My Drive/Deep Results/Database')\n",
        "\n",
        "list_rawdata = np.zeros((subject_numberT,task_number), dtype='object')\n",
        "\n",
        "for i in range(subject_numberT):\n",
        "  for j in range(task_number):\n",
        "    list_rawdata[i][j] = mne.io.read_raw_edf(list_raw_fnames[i][j], preload=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lltZvYULvrvA",
        "colab": {}
      },
      "source": [
        "subject_number = 90\n",
        "# new subject\n",
        "new_subject =np.arange(subject_number, subject_numberT)\n",
        "\n",
        "# img for each subject\n",
        "subject_img_number = math.floor((total_sampel_number - sampel_number_per_sec - (window_len-1 )*inner_sample_shift) / outer_sample_shift) +1\n",
        "np.random.seed(seed)  \n",
        "\n",
        "subject_number_array_shuffled=np.arange(subject_number)\n",
        "np.random.shuffle(subject_number_array_shuffled)\n",
        "\n",
        "subject_img_number_array_shuffled=np.arange(subject_img_number)\n",
        "np.random.shuffle(subject_img_number_array_shuffled)\n",
        "\n",
        "train_index = len(subject_img_number_array_shuffled)//2\n",
        "val_index = train_index + len(subject_img_number_array_shuffled)//4\n",
        "\n",
        "train_shuff = subject_img_number_array_shuffled[:train_index]\n",
        "val_shuff = subject_img_number_array_shuffled[train_index:val_index]\n",
        "test_shuff = subject_img_number_array_shuffled[val_index:]\n",
        "\n",
        "\n",
        "train_number = len(train_shuff)\n",
        "val_number = len(val_shuff)\n",
        "test_number = len(test_shuff)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NuDhT0Y1Fqa",
        "colab": {}
      },
      "source": [
        "def normalize_channel_data(ch , i, ch_min, ch_max):\n",
        "  ch = ((ch - ch_min[i]) / (ch_max[i] - ch_min[i] ))\n",
        "  return ch\n",
        "\n",
        "def ProjectionVector(VecA,VecB):\n",
        "    Projeted_VecB_on_VecA=np.dot(VecA,VecB)/np.dot(VecA,VecA)*VecA\n",
        "    return Projeted_VecB_on_VecA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyfUojlv76gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################################\n",
        "## Define General Data Generator\n",
        "def GenerateGeneralData(BatchSize,ListRawDataMain,SubjectArrayShuffled,ListChannel,RemoveBaseLineFlag,OrthogonalFlag,ImageArrayShuffled,WindowLen,OuterSampleShift,InnerSampleShift,SampelNumberPerSec):\n",
        "    \n",
        "    Iter=0\n",
        "    #ch_number=len(ListChannel)\n",
        "    \n",
        "    \n",
        "    ##########################################################\n",
        "    # Pre-Proceesing On Raw Data\n",
        "    ListRawDataTemp=ListRawDataMain.copy()\n",
        "    \n",
        "    DataAllChannelsRawPerSubject, times =(ListRawDataTemp[0][0][:64,:9600])\n",
        "\n",
        "    DataChannelsRaw   =np.zeros((len(SubjectArrayShuffled),ch_number,times.size),dtype = float)\n",
        "    DataChannelsNormal=np.zeros((len(SubjectArrayShuffled),ch_number,times.size),dtype = float)\n",
        "    DataChannelsOrt   =np.zeros((len(SubjectArrayShuffled),ch_number,times.size),dtype = float)\n",
        "    e= 0    \n",
        "    for s in SubjectArrayShuffled:\n",
        "\n",
        "        DataAllChannelsRawPerSubject, times =(ListRawDataTemp[s][0][:64,:9600])\n",
        "        \n",
        "        # Extrac Channel T9 or T10 as Baseline\n",
        "        DataChannelT9Raw =DataAllChannelsRawPerSubject[43]# Ch T9 (42) or T10 (43)\n",
        "\n",
        "\n",
        "        ch_max =[]\n",
        "        ch_min =[]\n",
        "        # Extract Selected Channels+ Remove Baseline+ Normailze\n",
        "        \n",
        "        for i in range(len(ListChannel)):\n",
        "            DataChannelsRaw[e][i]=DataAllChannelsRawPerSubject[ListChannel[i]].copy() -DataChannelT9Raw*RemoveBaseLineFlag\n",
        "\n",
        "            ch_max = np.append(ch_max, max(DataChannelsRaw[e][i])) # max for each cannel\n",
        "            ch_min = np.append(ch_min, min(DataChannelsRaw[e][i])) # min for each cannel\n",
        "\n",
        "            DataChannelsNormal[e][i]=normalize_channel_data(DataChannelsRaw[e][i].copy(), i, ch_min, ch_max)\n",
        "        e = e+1\n",
        "\n",
        "        # Orthogonal Channel\n",
        "        #DataChannelsOrt[e][0]=DataChannelsNormal[e][0]\n",
        "        #DataChannelsOrt[e][1]=DataChannelsNormal[e][1]-ProjectionVector(DataChannelsNormal[e][0].copy(),DataChannelsNormal[e][1].copy())*OrthogonalFlag\n",
        "        \n",
        "        \n",
        "        \n",
        "    ##########################################################\n",
        "    # Generate Data for Network\n",
        "    while True:\n",
        "\n",
        "      for j in ImageArrayShuffled:\n",
        "          r = 0\n",
        "          for s in SubjectArrayShuffled:\n",
        "\n",
        "              if Iter ==0:\n",
        "                  TrainImage=np.zeros((BatchSize, ch_number, WindowLen, SampelNumberPerSec), dtype = float)\n",
        "                  TrainLabel=np.zeros((BatchSize),dtype=int)\n",
        "\n",
        "              for i in range(len(ListChannel)):\n",
        "                  for z in range (WindowLen):\n",
        "                      ExtractedData = DataChannelsNormal[r][i][0+j*OuterSampleShift + z*InnerSampleShift:SampelNumberPerSec+ j*OuterSampleShift + z*InnerSampleShift]\n",
        "                      TrainImage[Iter][i][z] = ExtractedData.copy()# Data\n",
        "              r=r+1\n",
        "\n",
        "              TrainLabel[Iter] = s # label\n",
        "\n",
        "              Iter=Iter+1\n",
        "              #Count=Count+1\n",
        "              if Iter==BatchSize:\n",
        "                Iter=0\n",
        "                #print('Count=',Count)\n",
        "                TrainLabelClass=to_categorical(TrainLabel,subject_numberT)\n",
        "                TI = np.moveaxis(TrainImage, 1, -1)\n",
        "                yield TI, TrainLabelClass \n",
        "\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkHnIAbUCyGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ch_number=len(list_channel)\n",
        "list_rawdataTemp=list_rawdata.copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ccRoCsD68Sh",
        "colab_type": "code",
        "outputId": "057963d1-ce5c-4fc2-8f0c-e1c68f0558eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "#model = load_model('/content/drive/My Drive/mymodels/model2_2.h5')\n",
        "#model.summary()\n",
        "#model.pop()\n",
        "model.summary()\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 20, 160, 64)       11584     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 10, 80, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 8, 78, 128)        73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 39, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 2, 37, 256)        295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 18, 256)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               2359808   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "=================================================================\n",
            "Total params: 2,780,333\n",
            "Trainable params: 2,780,333\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0up45t3m2iAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-MFl09D2Scm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def subject_Predict_generator(mymodel, subject_arr, img_arr ):\n",
        "  sn = len(subject_arr)\n",
        "  imgn = len(img_arr)\n",
        "  #print(\"imgn\", imgn)\n",
        "  pre_GenTestData=GenerateGeneralData(BatchSize=batch_size,\n",
        "                                  ListRawDataMain=list_rawdataTemp.copy(),\n",
        "                                  SubjectArrayShuffled= subject_arr,\n",
        "                                  ListChannel=list_channel,\n",
        "                                  RemoveBaseLineFlag=RemoveBaseLine,\n",
        "                                  OrthogonalFlag=Orthogonal,\n",
        "                                  WindowLen=window_len,\n",
        "                                  OuterSampleShift=outer_sample_shift,\n",
        "                                  InnerSampleShift=inner_sample_shift,\n",
        "                                  SampelNumberPerSec=sampel_number_per_sec,\n",
        "                                  ImageArrayShuffled= img_arr)\n",
        "\n",
        "  pre_Subject = mymodel.predict_generator(pre_GenTestData,steps=np.ceil(imgn*sn/batch_size))\n",
        "  return pre_Subject\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeD67soc33qe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dacb4f5-5226-42f9-8fa2-a056a07c91ef"
      },
      "source": [
        "path = \"/content/drive/My Drive/random dist\"\n",
        "\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "except OSError:\n",
        "    print (\"Creation of the directory %s failed\" % path)\n",
        "else:\n",
        "    print (\"Successfully created the directory %s \" % path)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creation of the directory /content/drive/My Drive/random dist failed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4rbkvw1yvHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##  random instance\n",
        "\n",
        "num = 6\n",
        "list_dist =[]\n",
        "\n",
        "# subject 0 , instance 179\n",
        "pre_S1 = subject_Predict_generator(model, [0], [179])\n",
        "\n",
        "for i in range (109 ):\n",
        "\n",
        "  # subject i , random instance \n",
        "  pre_subject_arr = [i]\n",
        "  rand_sample = [random.randint(0,subject_img_number)]\n",
        "\n",
        "  ## Predict 2\n",
        "  pre_S2 = subject_Predict_generator(model, pre_subject_arr, rand_sample)\n",
        "\n",
        "  ##  Euclidea distance \n",
        "  d = distance.euclidean(pre_S1[0], pre_S2[0])\n",
        "  print(d)\n",
        "  list_dist.append(d)\n",
        "  \n",
        "print(len(list_dist))\n",
        "## Sort distance list\n",
        "#list_dist.sort()\n",
        "\n",
        "## Save in text file\n",
        "textFileName = \"textFile random dist_\"+str(num)+\".txt\"\n",
        "completeName = os.path.join(path, textFileName )\n",
        "\n",
        "with open(completeName, 'w') as f:\n",
        "  f.write( 'random dist:'  + '\\n')\n",
        "  f.writelines(str(j) + '\\n' for j in list_dist )\n",
        "  \n",
        "with open(completeName, 'r') as f:  \n",
        "  print(f.readlines(2) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}