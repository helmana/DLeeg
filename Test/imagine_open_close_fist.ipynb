{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "open close fist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helmana/DLeeg/blob/master/Test/imagine_open_close_fist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzGoH_NvCfsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "task :imagine open fist\n",
        "\n",
        "\n",
        "subject : 109\n",
        "channel : 64\n",
        "\n",
        "layers: 3 conv2D(3,3) & maxpooling(2,2) - 1 Dense(512) \n",
        "\n",
        "epoch: 30\n",
        "batch size: 20\n",
        "\n",
        "\n",
        "test acc: \n",
        "test loss: \n",
        "\n",
        "'''\n",
        "\n",
        "import matplotlib\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import random\n",
        "import mne\n",
        "from mne.preprocessing import create_ecg_epochs, create_eog_epochs\n",
        "from mne import io\n",
        "from mne import viz\n",
        "#from mne.datasets import testing\n",
        "from mne import Epochs, io, pick_types\n",
        "from mne.event import define_target_events\n",
        "from mne.time_frequency import psd_welch\n",
        "print(__doc__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjJggsfzzDfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subject_number=109\n",
        "task_index = [4,8,12] # task: imagine open & close fist\n",
        "task_number = len(task_index)\n",
        "ch_number = 64\n",
        "task_time = 60\n",
        "\n",
        "sampel_number_per_sec =  160 # sampel rate\n",
        "total_sampel_number =  sampel_number_per_sec *task_time # 60*160\n",
        "sample_shift = 4 #step len\n",
        "window_len= 20\n",
        "\n",
        "task_number"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSdyK2TBBwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# load dataset in array\n",
        "list_raw_fnames = [[0]*task_number]*subject_number\n",
        "for x in range(subject_number):\n",
        "    list_raw_fnames[x] = mne.datasets.eegbci.load_data(x+1,task_index)\n",
        "\n",
        "list_rawdata = np.zeros((subject_number,task_number), dtype='object')\n",
        "\n",
        "for i in range(subject_number):\n",
        "    for j in range(task_number):\n",
        "        list_rawdata[i][j] = mne.io.read_raw_edf(list_raw_fnames[i][j], preload=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-o3C85SCdW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img for each one\n",
        "subject_img_number = math.floor((total_sampel_number - sampel_number_per_sec) / sample_shift) +1 - window_len +1\n",
        "test_start_index=subject_img_number - math.floor(subject_img_number * 0.15) \n",
        "\n",
        "train_number =  test_start_index \n",
        "test_number = subject_img_number - test_start_index\n",
        "train_number"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOYdq7IiKlB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img = np.zeros((train_number*subject_number*task_number, ch_number, window_len + 1, 160), dtype = float)\n",
        "train_label =[]\n",
        "\n",
        "\n",
        "test_img = np.zeros((test_number*subject_number*task_number, ch_number, window_len, 160), dtype = float)\n",
        "test_label =[]\n",
        "\n",
        "\n",
        "train_img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17IfMp83MHec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def normalize_channel_data(ch , i, ch_min, ch_max):\n",
        "  ch = ((ch - ch_min[i]) / (ch_max[i] - ch_min[i] ))\n",
        "  return ch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNie-5LXRRKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_rawdataTest=list_rawdata.copy()\n",
        "for s in range(subject_number):\n",
        "  for t in range(task_number):\n",
        "    \n",
        "    DataChannelsRaw, times =list_rawdataTest[s][t][:64,:total_sampel_number]\n",
        "    \n",
        "    # make a copy\n",
        "    DataChannelsRaw_t=DataChannelsRaw.copy()\n",
        "    times_t=times.copy()\n",
        "    \n",
        "    # find min/max per channel\n",
        "    ch_max =[]\n",
        "    ch_min =[]\n",
        "    for p in range(len(DataChannelsRaw_t)):\n",
        "        ch_max = np.append(ch_max, max(DataChannelsRaw_t[p])) # max for each cannel\n",
        "        ch_min = np.append(ch_min, min(DataChannelsRaw_t[p])) # min for each cannel\n",
        "        \n",
        "    # Normalize Channels\n",
        "    DataChannelsNormal=np.zeros((ch_number,times.size),dtype = float)\n",
        "    for i in range(ch_number):\n",
        "        DataChannelsNormal[i]=normalize_channel_data(DataChannelsRaw_t[i], i, ch_min, ch_max)\n",
        "        \n",
        "\n",
        "    for j in range (subject_img_number):\n",
        "        for i in range(ch_number):\n",
        "            for z in range (window_len):\n",
        "              \n",
        "              ExtractedData = DataChannelsNormal[i,0+(j+z)*sample_shift:sampel_number_per_sec+(j+z)*sample_shift]\n",
        "              if j <test_start_index :\n",
        "                    train_img[s*task_number*train_number + t*train_number + j][i][z] = ExtractedData\n",
        "                    if z==window_len-1 :\n",
        "                      train_img[s*task_number*train_number + t*train_number + j][i][z+1] = s\n",
        "                      \n",
        "                      \n",
        "              else:\n",
        "                    test_img[s*task_number*test_number+ t*test_number + j - test_start_index][i][z] = ExtractedData\n",
        "        if j >=test_start_index :\n",
        "          test_label = np.append(test_label, (s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjQf8T_0ZETR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shaffle train img array\n",
        "train_img_shuffle = train_img.copy()\n",
        "\n",
        "np.random.shuffle(train_img_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90yZT_L-ZUAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img_2 = np.zeros((train_number*subject_number*task_number, ch_number, window_len, 160), dtype = float)\n",
        "\n",
        "# img label \n",
        "\n",
        "train_img_shuffle_len =len(train_img_shuffle)\n",
        "for i in range(train_img_shuffle_len):\n",
        "    train_label = np.append(train_label, (train_img_shuffle[i][0][window_len][0] ))\n",
        "    for j in range (ch_number):\n",
        "      train_img_2[i][j] = np.delete(train_img_shuffle[i][j], window_len, axis=0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORTLQiNzZbzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_label = to_categorical(train_label, subject_number)\n",
        "test_label = to_categorical(test_label, subject_number)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w45TPZNXZcdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_index = math.floor( len(train_img_2) * 0.2)\n",
        "\n",
        "\n",
        "# valid & train\n",
        "x_train =train_img_2[validation_index:]\n",
        "y_train =train_label[validation_index:]\n",
        "\n",
        "x_valid =train_img_2[:validation_index]\n",
        "y_valid =train_label[:validation_index]\n",
        "\n",
        "x_valid.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAjYZx7hZrs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu', padding='same', input_shape = (ch_number,window_len,160), data_format= \"channels_first\" ))\n",
        "print(model.output.shape)\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "print(model.output.shape)\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "print(model.output.shape)\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "print(model.output.shape)\n",
        "model.add(layers.Conv2D(256, (3,3), activation = 'relu'))\n",
        "print(model.output.shape)\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "print(model.output.shape)\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "print(model.output.shape)\n",
        "model.add(layers.Dense(subject_number, activation = 'softmax'))\n",
        "print(model.output.shape)\n",
        "\n",
        "#compile\n",
        "model.compile(loss= 'categorical_crossentropy',\n",
        "              optimizer= optimizers.RMSprop(lr= 1e-4),\n",
        "              metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HfdiGI4EDUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        ",\n",
        "history = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        epochs = 30,\n",
        "        batch_size = 20,\n",
        "        validation_data = (x_valid, y_valid)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1CTywIlZ_vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(test_img, test_label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CzALXHfaA1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history \n",
        "\n",
        "loss_values = history_dict ['loss'] \n",
        "\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss') \n",
        "\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss') \n",
        "\n",
        "plt.title('Training and validation loss') \n",
        "\n",
        "plt.xlabel('Epochs') \n",
        "\n",
        "plt.ylabel('Loss') \n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4RwQGuKaUQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history \n",
        "\n",
        "acc_values = history_dict ['acc'] \n",
        "\n",
        "val_acc_values = history_dict['val_acc']\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc') \n",
        "\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc') \n",
        "\n",
        "plt.title('Training and validation acc') \n",
        "\n",
        "plt.xlabel('Epochs') \n",
        "\n",
        "plt.ylabel('acc') \n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}